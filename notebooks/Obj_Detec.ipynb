{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ob5vEU1U0Twv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978d41d5-1068-4ec5-dfa0-186f323a50c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "--2024-06-30 18:49:37--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 146836934 (140M) [application/octet-stream]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>] 140.03M   178MB/s    in 0.8s    \n",
            "\n",
            "2024-06-30 18:49:38 (178 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [146836934/146836934]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.12/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "modified      /root/.bashrc\n",
            "\n",
            "==> For changes to take effect, close and re-open your current shell. <==\n",
            "\n",
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    anaconda-anon-usage-0.4.4  | py39hfc0e8ea_100          25 KB\n",
            "    boltons-23.0.0             |   py39h06a4308_0         426 KB\n",
            "    brotli-python-1.0.9        |   py39h6a678d5_8         359 KB\n",
            "    certifi-2024.6.2           |   py39h06a4308_0         160 KB\n",
            "    cffi-1.16.0                |   py39h5eee18b_1         251 KB\n",
            "    conda-24.5.0               |   py39h06a4308_0         968 KB\n",
            "    conda-content-trust-0.2.0  |   py39h06a4308_1          51 KB\n",
            "    conda-package-handling-2.3.0|   py39h06a4308_0         269 KB\n",
            "    conda-package-streaming-0.10.0|   py39h06a4308_0          27 KB\n",
            "    cryptography-42.0.5        |   py39hdda0065_1         2.1 MB\n",
            "    distro-1.9.0               |   py39h06a4308_0          31 KB\n",
            "    frozendict-2.4.2           |   py39h5eee18b_0          55 KB\n",
            "    idna-3.7                   |   py39h06a4308_0         113 KB\n",
            "    jsonpatch-1.33             |   py39h06a4308_1          31 KB\n",
            "    libmambapy-1.5.8           |   py39h2dafd23_2         327 KB\n",
            "    menuinst-2.1.1             |   py39h06a4308_0         222 KB\n",
            "    packaging-23.2             |   py39h06a4308_0         145 KB\n",
            "    pip-24.0                   |   py39h06a4308_0         2.6 MB\n",
            "    platformdirs-3.10.0        |   py39h06a4308_0          33 KB\n",
            "    pluggy-1.0.0               |   py39h06a4308_1          28 KB\n",
            "    pybind11-abi-4             |       hd3eb1b0_1          14 KB\n",
            "    pycosat-0.6.6              |   py39h5eee18b_1          93 KB\n",
            "    pysocks-1.7.1              |   py39h06a4308_0          31 KB\n",
            "    python-3.9.19              |       h955ad1f_1        25.1 MB\n",
            "    requests-2.32.2            |   py39h06a4308_0         101 KB\n",
            "    ruamel.yaml-0.17.21        |   py39h5eee18b_0         178 KB\n",
            "    ruamel.yaml.clib-0.2.6     |   py39h5eee18b_1         140 KB\n",
            "    setuptools-69.5.1          |   py39h06a4308_0        1003 KB\n",
            "    tqdm-4.66.4                |   py39h2f386ee_0         133 KB\n",
            "    urllib3-2.2.2              |   py39h06a4308_0         177 KB\n",
            "    wheel-0.43.0               |   py39h06a4308_0         109 KB\n",
            "    zstandard-0.22.0           |   py39h2c38b39_0         427 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        35.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  ruamel.yaml.clib   pkgs/main/linux-64::ruamel.yaml.clib-0.2.6-py39h5eee18b_1 \n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  truststore-0.8.0-py312h06a4308_0\n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  anaconda-anon-usa~                0.4.4-py312hfc0e8ea_100 --> 0.4.4-py39hfc0e8ea_100 \n",
            "  boltons                            23.0.0-py312h06a4308_0 --> 23.0.0-py39h06a4308_0 \n",
            "  brotli-python                       1.0.9-py312h6a678d5_8 --> 1.0.9-py39h6a678d5_8 \n",
            "  certifi                          2024.6.2-py312h06a4308_0 --> 2024.6.2-py39h06a4308_0 \n",
            "  cffi                               1.16.0-py312h5eee18b_1 --> 1.16.0-py39h5eee18b_1 \n",
            "  conda                              24.5.0-py312h06a4308_0 --> 24.5.0-py39h06a4308_0 \n",
            "  conda-content-tru~                  0.2.0-py312h06a4308_1 --> 0.2.0-py39h06a4308_1 \n",
            "  conda-package-han~                  2.3.0-py312h06a4308_0 --> 2.3.0-py39h06a4308_0 \n",
            "  conda-package-str~                 0.10.0-py312h06a4308_0 --> 0.10.0-py39h06a4308_0 \n",
            "  cryptography                       42.0.5-py312hdda0065_1 --> 42.0.5-py39hdda0065_1 \n",
            "  distro                              1.9.0-py312h06a4308_0 --> 1.9.0-py39h06a4308_0 \n",
            "  frozendict                          2.4.2-py312h06a4308_0 --> 2.4.2-py39h5eee18b_0 \n",
            "  idna                                  3.7-py312h06a4308_0 --> 3.7-py39h06a4308_0 \n",
            "  jsonpatch                            1.33-py312h06a4308_1 --> 1.33-py39h06a4308_1 \n",
            "  libmambapy                          1.5.8-py312h2dafd23_2 --> 1.5.8-py39h2dafd23_2 \n",
            "  menuinst                            2.1.1-py312h06a4308_0 --> 2.1.1-py39h06a4308_0 \n",
            "  packaging                            23.2-py312h06a4308_0 --> 23.2-py39h06a4308_0 \n",
            "  pip                                  24.0-py312h06a4308_0 --> 24.0-py39h06a4308_0 \n",
            "  platformdirs                       3.10.0-py312h06a4308_0 --> 3.10.0-py39h06a4308_0 \n",
            "  pluggy                              1.0.0-py312h06a4308_1 --> 1.0.0-py39h06a4308_1 \n",
            "  pybind11-abi                                 5-hd3eb1b0_0 --> 4-hd3eb1b0_1 \n",
            "  pycosat                             0.6.6-py312h5eee18b_1 --> 0.6.6-py39h5eee18b_1 \n",
            "  pysocks                             1.7.1-py312h06a4308_0 --> 1.7.1-py39h06a4308_0 \n",
            "  python                                  3.12.4-h5148396_1 --> 3.9.19-h955ad1f_1 \n",
            "  requests                           2.32.2-py312h06a4308_0 --> 2.32.2-py39h06a4308_0 \n",
            "  ruamel.yaml                       0.17.21-py312h5eee18b_0 --> 0.17.21-py39h5eee18b_0 \n",
            "  setuptools                         69.5.1-py312h06a4308_0 --> 69.5.1-py39h06a4308_0 \n",
            "  tqdm                               4.66.4-py312he106c6f_0 --> 4.66.4-py39h2f386ee_0 \n",
            "  urllib3                             2.2.2-py312h06a4308_0 --> 2.2.2-py39h06a4308_0 \n",
            "  wheel                              0.43.0-py312h06a4308_0 --> 0.43.0-py39h06a4308_0 \n",
            "  zstandard                          0.22.0-py312h2c38b39_0 --> 0.22.0-py39h2c38b39_0 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/py39\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.3.11-h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-3.0.14-h5eee18b_0 \n",
            "  pip                pkgs/main/linux-64::pip-24.0-py39h06a4308_0 \n",
            "  python             pkgs/main/linux-64::python-3.9.19-h955ad1f_1 \n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-69.5.1-py39h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
            "  tzdata             pkgs/main/noarch::tzdata-2024a-h04d1e81_0 \n",
            "  wheel              pkgs/main/linux-64::wheel-0.43.0-py39h06a4308_0 \n",
            "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Python 3.9.19\n",
            "--2024-06-30 18:50:32--  https://raw.githubusercontent.com/airctic/icevision/master/icevision_install.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2820 (2.8K) [text/plain]\n",
            "Saving to: ‘icevision_install.sh’\n",
            "\n",
            "icevision_install.s 100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-30 18:50:33 (51.8 MB/s) - ‘icevision_install.sh’ saved [2820/2820]\n",
            "\n",
            "Installing icevision + dependencices for cuda11\n",
            "- Installing torch and its dependencies\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp39-cp39-linux_x86_64.whl (2137.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 GB\u001b[0m \u001b[31m593.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.11.1+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.1%2Bcu111-cp39-cp39-linux_x86_64.whl (24.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.11.0\n",
            "  Downloading torchtext-0.11.0-cp39-cp39-manylinux1_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting typing-extensions (from torch==1.10.0+cu111)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting numpy (from torchvision==0.11.1+cu111)\n",
            "  Downloading numpy-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.0,>=5.3.0 (from torchvision==0.11.1+cu111)\n",
            "  Downloading pillow-10.3.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from torchtext==0.11.0) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from torchtext==0.11.0) (2.32.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->torchtext==0.11.0) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->torchtext==0.11.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->torchtext==0.11.0) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->torchtext==0.11.0) (2024.6.2)\n",
            "Downloading torchtext-0.11.0-cp39-cp39-manylinux1_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.3.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-extensions, pillow, numpy, torch, torchvision, torchtext\n",
            "Successfully installed numpy-2.0.0 pillow-10.3.0 torch-1.10.0+cu111 torchtext-0.11.0 torchvision-0.11.1+cu111 typing-extensions-4.12.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m- Installing mmcv\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.9/738.9 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m- Installing mmdet\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.9/432.9 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.0/305.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m- Installing mmseg\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.4/686.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m- Installing icevision from master\n",
            "\u001b[33mDEPRECATION: git+https://github.com/airctic/icevision.git#egg=icevision[all] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.2/111.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/112.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.2/808.2 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.8/436.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.8/912.8 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.4/492.4 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m937.8/937.8 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.3/304.3 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for icevision (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m- Installing icedata from master\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for icedata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.11.41, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.5.2.52, 4.5.5.62, 4.7.0.68, 4.8.0.74\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python-headless==4.1.2.30 (from versions: 3.4.10.37, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.14.51, 3.4.14.53, 3.4.15.55, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.46, 4.5.1.48, 4.5.2.54, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python-headless==4.1.2.30\u001b[0m\u001b[31m\n",
            "\u001b[0micevision installation finished!\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local\n",
        "\n",
        "!conda init\n",
        "!conda install -q python=3.9\n",
        "!conda create -q --name py39 python=3.9\n",
        "!source  activate py39\n",
        "!python --version\n",
        "# Torch - Torchvision - IceVision - IceData - MMDetection - YOLOv5 - EfficientDet Installation\n",
        "!wget https://raw.githubusercontent.com/airctic/icevision/master/icevision_install.sh\n",
        "\n",
        "# Choose your installation target: cuda11 or cuda10 or cpu\n",
        "!bash icevision_install.sh cuda11 master\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!kaggle datasets download -q -d tarunbisht11/yolo-animal-detection-small\n",
        "!unzip yolo-animal-detection-small.zip  -d data\n",
        "!rm yolo-animal-detection-small.zip"
      ],
      "metadata": {
        "id": "JHRDu0Zf3PVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a653a3-7326-498f-f85e-d8f5b1c591e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/82.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mDataset URL: https://www.kaggle.com/datasets/tarunbisht11/yolo-animal-detection-small\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Archive:  yolo-animal-detection-small.zip\n",
            "  inflating: data/test.csv           \n",
            "  inflating: data/test.record        \n",
            "  inflating: data/train.csv          \n",
            "  inflating: data/train.record       \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_000.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_000.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_007.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_007.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_050.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_050.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_072.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_072.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_076.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_076.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_079.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_079.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_088.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_088.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_091.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_091.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_099.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_099.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_100.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_100.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_and_monkeys_000.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_and_monkeys_000.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_and_monkeys_002.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_and_monkeys_002.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_and_monkeys_029.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_and_monkeys_029.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_031.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_031.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_039.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_039.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_057.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_057.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_090.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_090.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_092.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/cats_groups_092.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dog_and_monkey_035.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dog_and_monkey_035.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dog_and_monkey_046.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dog_and_monkey_046.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dog_and_monkey_049.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dog_and_monkey_049.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_033.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_033.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_042.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_042.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_062.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_062.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_070.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_070.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_072.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_072.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_079.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_079.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_086.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_086.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_089.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_089.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_093.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_093.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_014.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_014.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_021.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_021.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_043.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_043.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_059.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_059.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_079.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_079.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_093.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_and_cats_093.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_groups_009.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_groups_009.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_groups_012.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/dogs_groups_012.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkey_groups_005.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkey_groups_005.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkey_groups_023.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkey_groups_023.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkey_groups_056.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkey_groups_056.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkey_groups_061.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkey_groups_061.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_001.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_001.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_019.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_019.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_022.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_022.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_027.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_027.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_037.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_037.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_038.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_038.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_085.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_085.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_088.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_088.xml  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_093.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/test/monkeys_093.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_001.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_001.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_002.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_002.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_003.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_003.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_004.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_004.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_005.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_005.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_006.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_006.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_008.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_008.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_009.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_009.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_010.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_010.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_011.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_011.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_012.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_012.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_013.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_013.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_014.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_014.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_015.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_015.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_016.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_016.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_017.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_017.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_018.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_018.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_019.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_019.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_021.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_021.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_022.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_022.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_023.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_023.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_024.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_024.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_025.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_025.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_026.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_026.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_027.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_027.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_028.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_028.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_029.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_029.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_030.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_030.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_031.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_031.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_032.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_032.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_033.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_033.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_034.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_034.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_035.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_035.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_036.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_036.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_037.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_037.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_038.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_038.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_039.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_039.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_040.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_040.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_041.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_041.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_042.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_042.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_043.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_043.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_044.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_044.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_045.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_045.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_046.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_046.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_047.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_047.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_048.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_048.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_049.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_049.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_052.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_052.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_053.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_053.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_055.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_055.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_056.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_056.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_058.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_058.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_059.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_059.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_060.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_060.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_061.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_061.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_062.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_062.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_063.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_063.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_064.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_064.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_065.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_065.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_067.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_067.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_068.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_068.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_069.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_069.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_070.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_070.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_071.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_071.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_073.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_073.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_074.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_074.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_075.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_075.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_077.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_077.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_078.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_078.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_080.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_080.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_081.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_081.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_082.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_082.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_083.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_083.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_084.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_084.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_085.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_085.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_086.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_086.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_087.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_087.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_089.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_089.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_090.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_090.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_092.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_092.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_093.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_093.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_094.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_094.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_095.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_095.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_096.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_096.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_097.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_097.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_098.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_098.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_001.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_001.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_004.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_004.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_009.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_009.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_011.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_011.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_015.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_015.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_017.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_017.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_018.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_018.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_019.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_019.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_021.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_021.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_022.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_022.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_023.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_023.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_024.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_024.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_025.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_025.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_028.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_028.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_030.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_030.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_039.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_039.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_041.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_041.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_042.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_042.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_044.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_044.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_047.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_047.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_054.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_054.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_057.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_057.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_064.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_064.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_068.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_068.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_071.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_071.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_085.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_085.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_088.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_088.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_089.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_089.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_091.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_091.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_093.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_093.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_097.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_and_monkeys_097.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_000.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_000.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_001.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_001.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_002.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_002.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_003.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_003.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_005.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_005.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_006.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_006.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_007.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_007.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_008.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_008.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_009.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_009.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_010.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_010.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_011.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_011.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_012.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_012.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_016.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_016.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_018.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_018.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_021.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_021.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_022.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_022.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_026.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_026.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_027.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_027.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_028.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_028.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_030.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_030.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_033.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_033.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_035.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_035.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_036.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_036.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_037.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_037.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_040.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_040.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_043.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_043.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_044.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_044.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_047.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_047.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_053.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_053.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_055.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_055.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_056.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_056.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_058.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_058.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_059.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_059.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_060.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_060.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_065.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_065.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_066.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_066.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_067.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_067.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_070.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_070.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_071.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_071.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_072.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_072.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_080.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_080.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_083.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_083.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_091.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_091.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_093.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_093.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_096.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_096.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_097.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/cats_groups_097.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_000.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_000.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_001.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_001.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_003.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_003.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_005.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_005.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_012.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_012.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_014.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_014.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_016.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_016.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_019.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_019.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_022.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_022.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_023.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_023.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_024.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_024.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_028.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_028.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_031.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_031.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_032.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_032.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_033.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_033.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_034.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_034.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_039.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_039.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_040.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_040.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_042.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_042.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_043.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_043.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_045.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_045.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_048.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_048.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_050.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_050.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_053.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_053.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_057.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_057.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_063.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_063.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_065.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_065.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_078.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_078.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_081.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_081.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_085.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_085.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_089.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dog_and_monkey_089.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_000.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_000.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_001.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_001.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_002.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_002.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_003.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_003.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_004.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_004.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_005.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_005.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_006.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_006.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_007.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_007.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_008.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_008.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_009.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_009.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_010.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_010.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_011.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_011.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_012.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_012.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_013.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_013.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_014.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_014.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_015.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_015.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_016.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_016.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_018.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_018.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_019.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_019.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_020.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_020.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_021.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_021.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_023.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_023.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_024.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_024.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_025.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_025.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_026.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_026.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_027.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_027.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_028.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_028.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_029.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_029.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_030.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_030.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_031.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_031.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_032.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_032.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_034.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_034.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_036.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_036.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_037.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_037.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_039.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_039.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_040.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_040.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_041.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_041.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_043.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_043.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_044.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_044.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_045.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_045.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_046.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_046.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_047.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_047.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_049.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_049.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_050.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_050.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_051.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_051.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_052.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_052.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_053.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_053.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_054.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_054.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_055.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_055.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_056.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_056.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_057.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_057.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_058.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_058.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_060.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_060.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_061.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_061.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_063.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_063.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_064.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_064.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_065.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_065.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_066.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_066.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_067.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_067.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_068.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_068.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_069.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_069.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_071.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_071.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_073.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_073.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_074.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_074.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_075.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_075.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_076.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_076.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_077.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_077.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_078.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_078.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_081.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_081.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_082.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_082.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_083.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_083.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_084.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_084.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_087.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_087.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_088.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_088.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_090.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_090.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_091.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_091.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_092.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_092.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_094.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_094.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_095.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_095.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_096.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_096.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_097.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_097.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_099.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_099.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_000.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_000.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_002.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_002.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_005.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_005.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_006.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_006.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_010.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_010.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_011.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_011.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_012.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_012.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_013.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_013.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_015.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_015.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_018.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_018.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_020.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_020.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_023.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_023.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_024.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_024.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_025.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_025.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_026.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_026.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_027.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_027.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_029.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_029.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_031.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_031.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_033.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_033.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_034.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_034.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_035.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_035.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_036.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_036.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_038.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_038.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_039.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_039.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_040.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_040.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_042.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_042.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_044.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_044.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_045.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_045.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_046.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_046.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_048.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_048.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_052.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_052.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_053.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_053.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_054.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_054.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_056.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_056.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_057.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_057.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_066.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_066.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_069.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_069.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_070.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_070.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_071.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_071.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_073.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_073.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_075.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_075.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_076.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_076.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_081.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_081.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_083.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_083.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_084.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_084.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_086.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_086.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_088.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_088.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_089.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_089.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_090.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_090.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_092.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_092.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_094.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_094.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_095.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_095.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_097.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_097.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_098.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_and_cats_098.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_002.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_002.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_004.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_004.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_005.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_005.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_007.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_007.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_017.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_017.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_018.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_018.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_019.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_019.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_020.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_020.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_022.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_022.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_026.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_026.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_049.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_049.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_053.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_053.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_057.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_057.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_063.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_063.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_066.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_066.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_077.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_077.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_081.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_081.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_082.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_082.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_085.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_085.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_088.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_088.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_089.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/dogs_groups_089.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_000.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_000.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_001.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_001.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_002.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_002.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_003.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_003.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_004.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_004.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_007.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_007.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_009.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_009.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_013.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_013.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_014.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_014.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_015.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_015.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_016.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_016.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_017.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_017.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_018.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_018.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_020.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_020.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_021.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_021.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_022.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_022.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_024.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_024.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_025.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_025.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_026.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_026.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_028.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_028.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_030.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_030.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_043.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_043.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_045.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_045.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_050.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_050.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_055.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_055.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_057.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_057.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_059.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_059.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_060.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_060.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_066.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_066.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_070.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_070.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_072.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_072.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_074.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_074.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_078.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_078.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_082.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_082.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_083.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_083.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_084.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_084.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_093.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_093.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_095.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_095.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_097.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_097.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_099.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkey_groups_099.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_000.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_000.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_002.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_002.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_003.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_003.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_004.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_004.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_005.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_005.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_006.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_006.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_007.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_007.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_008.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_008.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_009.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_009.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_011.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_011.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_012.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_012.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_013.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_013.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_014.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_014.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_015.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_015.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_016.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_016.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_017.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_017.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_018.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_018.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_021.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_021.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_023.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_023.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_024.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_024.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_025.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_025.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_026.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_026.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_028.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_028.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_029.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_029.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_030.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_030.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_031.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_031.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_032.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_032.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_034.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_034.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_035.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_035.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_036.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_036.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_039.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_039.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_040.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_040.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_041.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_041.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_042.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_042.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_043.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_043.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_044.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_044.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_045.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_045.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_049.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_049.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_050.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_050.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_051.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_051.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_052.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_052.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_053.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_053.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_054.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_054.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_056.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_056.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_057.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_057.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_058.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_058.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_061.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_061.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_063.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_063.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_064.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_064.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_066.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_066.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_067.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_067.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_068.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_068.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_069.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_069.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_070.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_070.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_071.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_071.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_072.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_072.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_073.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_073.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_075.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_075.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_076.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_076.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_077.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_077.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_078.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_078.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_079.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_079.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_080.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_080.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_082.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_082.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_083.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_083.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_084.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_084.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_086.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_086.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_087.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_087.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_089.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_089.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_090.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_090.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_091.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_091.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_092.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_092.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_094.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_094.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_095.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_095.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_097.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_097.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_098.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_098.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_099.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_099.xml  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_100.jpg  \n",
            "  inflating: data/yolo-animal-detection-small/train/monkeys_100.xml  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overwrite utils.py\n",
        "\n"
      ],
      "metadata": {
        "id": "d6Eto30plyYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /usr/local/lib/python3.9/site-packages/icevision/visualize/utils.py\n",
        "__all__ = [\n",
        "    \"draw_label\",\n",
        "    \"bbox_polygon\",\n",
        "    \"draw_mask\",\n",
        "    \"as_rgb_tuple\",\n",
        "    \"get_default_font\",\n",
        "    \"rand_cmap\",\n",
        "]\n",
        "\n",
        "from icevision.imports import *\n",
        "from icevision.utils import *\n",
        "from matplotlib import patches\n",
        "from PIL import Image, ImageFont, ImageDraw\n",
        "import PIL\n",
        "\n",
        "\n",
        "def draw_label(ax, x, y, name, color, fontsize=18):\n",
        "    ax.text(\n",
        "        x + 1,\n",
        "        y - 2,\n",
        "        name,\n",
        "        fontsize=fontsize,\n",
        "        color=\"white\",\n",
        "        va=\"bottom\",\n",
        "        bbox=dict(facecolor=color, edgecolor=color, pad=2, alpha=0.9),\n",
        "    )\n",
        "\n",
        "\n",
        "def bbox_polygon(bbox):\n",
        "    bx, by, bw, bh = bbox.xywh\n",
        "    poly = np.array([[bx, by], [bx, by + bh], [bx + bw, by + bh], [bx + bw, by]])\n",
        "    return patches.Polygon(poly)\n",
        "\n",
        "\n",
        "def draw_mask(ax, mask, color):\n",
        "    color_mask = np.ones((*mask.shape, 3)) * color\n",
        "    ax.imshow(np.dstack((color_mask, mask * 0.5)))\n",
        "    ax.contour(mask, colors=[color_mask[0, 0, :]], alpha=0.4)\n",
        "\n",
        "\n",
        "def as_rgb_tuple(x: Union[np.ndarray, tuple, list, str]) -> tuple:\n",
        "    \"Convert np RGB values -> tuple for PIL compatibility\"\n",
        "    if isinstance(x, (np.ndarray, tuple, list)):\n",
        "        if not len(x) == 3:\n",
        "            raise ValueError(f\"Expected 3 (RGB) numbers, got {len(x)}\")\n",
        "        if isinstance(x, np.ndarray):\n",
        "            return tuple(x.astype(np.int32))\n",
        "        elif isinstance(x, tuple):\n",
        "            return x\n",
        "        elif isinstance(x, list):\n",
        "            return tuple(x)\n",
        "    elif isinstance(x, str):\n",
        "        return PIL.ImageColor.getrgb(x)\n",
        "    else:\n",
        "        raise ValueError(f\"Expected {{np.ndarray|list|tuple}}, got {type(x)}\")\n",
        "\n",
        "\n",
        "def get_default_font() -> str:\n",
        "    import requests\n",
        "\n",
        "    font_dir = get_root_dir() / \"fonts\"\n",
        "    font_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    font_file = font_dir / \"SpaceGrotesk-Medium.ttf\"\n",
        "    if not font_file.exists():\n",
        "        URL = \"https://raw.githubusercontent.com/airctic/storage/master/SpaceGrotesk-Medium.ttf\"\n",
        "        logger.info(\n",
        "            \"Downloading default `.ttf` font file - SpaceGrotesk-Medium.ttf from {} to {}\",\n",
        "            URL,\n",
        "            font_file,\n",
        "        )\n",
        "        font_file.write_bytes(requests.get(URL).content)\n",
        "    return str(font_file)\n",
        "\n",
        "\n",
        "# Generate random colormap from https://stackoverflow.com/questions/14720331/how-to-generate-random-colors-in-matplotlib/32520273#32520273\n",
        "def rand_cmap(\n",
        "    nlabels,\n",
        "    type=\"bright\",\n",
        "    first_color_black=True,\n",
        "    last_color_black=False,\n",
        "    verbose=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Creates a random colormap to be used together with matplotlib. Useful for segmentation tasks\n",
        "    :param nlabels: Number of labels (size of colormap)\n",
        "    :param type: 'bright' for strong colors, 'soft' for pastel colors\n",
        "    :param first_color_black: Option to use first color as black, True or False\n",
        "    :param last_color_black: Option to use last color as black, True or False\n",
        "    :param verbose: Prints the number of labels and shows the colormap. True or False\n",
        "    :return: colormap for matplotlib\n",
        "    \"\"\"\n",
        "    from matplotlib.colors import LinearSegmentedColormap\n",
        "    import colorsys\n",
        "\n",
        "    np.random.seed(49)\n",
        "\n",
        "    if type not in (\"bright\", \"soft\"):\n",
        "        print('Please choose \"bright\" or \"soft\" for type')\n",
        "        return\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Number of labels: \" + str(nlabels))\n",
        "\n",
        "    # Generate color map for bright colors, based on hsv\n",
        "    if type == \"bright\":\n",
        "        randHSVcolors = [\n",
        "            (\n",
        "                np.random.uniform(low=0.0, high=1),\n",
        "                np.random.uniform(low=0.2, high=1),\n",
        "                np.random.uniform(low=0.9, high=1),\n",
        "            )\n",
        "            for i in range(nlabels)\n",
        "        ]\n",
        "\n",
        "        # Convert HSV list to RGB\n",
        "        randRGBcolors = []\n",
        "        for HSVcolor in randHSVcolors:\n",
        "            randRGBcolors.append(\n",
        "                colorsys.hsv_to_rgb(HSVcolor[0], HSVcolor[1], HSVcolor[2])\n",
        "            )\n",
        "\n",
        "        if first_color_black:\n",
        "            randRGBcolors[0] = [0, 0, 0]\n",
        "\n",
        "        if last_color_black:\n",
        "            randRGBcolors[-1] = [0, 0, 0]\n",
        "\n",
        "        random_colormap = LinearSegmentedColormap.from_list(\n",
        "            \"new_map\", randRGBcolors, N=nlabels\n",
        "        )\n",
        "\n",
        "    # Generate soft pastel colors, by limiting the RGB spectrum\n",
        "    if type == \"soft\":\n",
        "        low = 0.6\n",
        "        high = 0.95\n",
        "        randRGBcolors = [\n",
        "            (\n",
        "                np.random.uniform(low=low, high=high),\n",
        "                np.random.uniform(low=low, high=high),\n",
        "                np.random.uniform(low=low, high=high),\n",
        "            )\n",
        "            for i in range(nlabels)\n",
        "        ]\n",
        "\n",
        "        if first_color_black:\n",
        "            randRGBcolors[0] = [0, 0, 0]\n",
        "\n",
        "        if last_color_black:\n",
        "            randRGBcolors[-1] = [0, 0, 0]\n",
        "        random_colormap = LinearSegmentedColormap.from_list(\n",
        "            \"new_map\", randRGBcolors, N=nlabels\n",
        "        )\n",
        "\n",
        "    # Display colorbar\n",
        "    if verbose:\n",
        "        from matplotlib import colors, colorbar\n",
        "        from matplotlib import pyplot as plt\n",
        "\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(15, 0.5))\n",
        "\n",
        "        bounds = np.linspace(0, nlabels, nlabels + 1)\n",
        "        norm = colors.BoundaryNorm(bounds, nlabels)\n",
        "\n",
        "        cb = colorbar.ColorbarBase(\n",
        "            ax,\n",
        "            cmap=random_colormap,\n",
        "            norm=norm,\n",
        "            spacing=\"proportional\",\n",
        "            ticks=None,\n",
        "            boundaries=bounds,\n",
        "            format=\"%1i\",\n",
        "            orientation=\"horizontal\",\n",
        "        )\n",
        "\n",
        "    return random_colormap\n"
      ],
      "metadata": {
        "id": "8D5R6bOIl7z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train model\n"
      ],
      "metadata": {
        "id": "oF1LDy254nWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import fastai.vision\n",
        "import fastai.vision.all\n",
        "from icevision.all import *\n",
        "from icevision.models import *\n",
        "import os\n",
        "from icevision.core import BaseRecord\n",
        "import pandas as pd\n",
        "import fastai\n",
        "\n",
        "row_traincsv_data_path = os.path.join(r\"/content/data/train.csv\")\n",
        "df = pd.read_csv(row_traincsv_data_path)\n",
        "\n",
        "df.rename(columns={\"class\":\"label\"},inplace=True)\n",
        "\n",
        "train_annotation_path = os.path.join(r\"/content/data/yolo-animal-detection-small\",\"train_annotation.csv\")\n",
        "df.to_csv(train_annotation_path,index=False)\n",
        "df = pd.read_csv(train_annotation_path)\n",
        "\n",
        "template_record = ObjectDetectionRecord()\n",
        "\n",
        "class AmDetec(Parser):\n",
        "    def __init__(self,template_record):\n",
        "        super().__init__(template_record=template_record)\n",
        "\n",
        "        self.df = pd.read_csv(train_annotation_path)\n",
        "        self.class_map = ClassMap(list(self.df[\"label\"].unique())) # {\"background\":0,\"cat\":1,\"dog\":2}\n",
        "\n",
        "    def __iter__(self) -> Any:\n",
        "        for o in self.df.itertuples():\n",
        "            yield o   #จะคืนค่าทีละแถวแทนที่จะคืนค่าทั้งหมดในคราวเดียว\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def record_id(self,o) -> Hashable:\n",
        "        return o.filename\n",
        "    def parse_fields(self, o, record, is_new):\n",
        "        if is_new:\n",
        "            record.set_filepath(os.path.join(r\"/content/data/yolo-animal-detection-small\",\"train\",o.filename)) #setไฟล์pathเพื่อ train\n",
        "            record.set_img_size(ImgSize(width=o.width,height=o.height))\n",
        "            record.detection.set_class_map(self.class_map)\n",
        "        record.detection.add_bboxes([BBox.from_xyxy(o.xmin,o.ymin,o.xmax,o.ymax)])\n",
        "        record.detection.add_labels([o.label])\n",
        "\n",
        "parser = AmDetec(template_record=template_record)\n",
        "train_record,val_record = parser.parse()\n",
        "model_type = models.mmdet.retinanet\n",
        "backbone = model_type.backbones.resnet50_fpn_1x\n",
        "\n",
        "train_tramform = tfms.A.Adapter([*tfms.A.aug_tfms(size=224,presize=512),tfms.A.Normalize()])\n",
        "valid_tramform = tfms.A.Adapter([*tfms.A.resize_and_pad(224),tfms.A.Normalize])\n",
        "\n",
        "\n",
        "train_set = Dataset(train_record,train_tramform)\n",
        "val_set = Dataset(val_record,valid_tramform)\n",
        "\n",
        "train_dl = model_type.train_dl(train_set,batch_size=8,num_workers=4,shuffle =True)\n",
        "val_dl = model_type.train_dl(train_set,batch_size=8,num_workers=4,shuffle =False)\n",
        "\n",
        "\n",
        "\n",
        "model = model_type.model(backbone=backbone(pretrained=True),num_classes=len(parser.class_map)) # model_type คือ object detection model ของเราชื่ออะไร ส่่วน classification เป็นตัส backbone\n",
        "\n",
        "\n",
        "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)] #mAP score\n",
        "\n",
        "#ใช้ fast AI ในการ train model\n",
        "\n",
        "csv_logger = fastai.vision.all.CSVLogger(fname='training_log.csv')\n",
        "\n",
        "# เพิ่ม COCOMetric ใน callbacks เพื่อบันทึกค่า AP และ AR ในแต่ละ epoch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "learner = model_type.fastai.learner(dls=[train_dl,val_dl],model=model,metrics=metrics,cbs=csv_logger)\n",
        "\n",
        "#lr = learner.lr_find()\n",
        "#print(lr)\n",
        "#learner.fine_tune(5,1e-4,freeze_epochs=1)\n",
        "learner.fine_tune(50, 7e-5, freeze_epochs=1)\n",
        "m = ClassMap(list(df['label'].unique()))\n",
        "m.get_classes()\n",
        "\n",
        "checkpoint_path = \"monkeycatdog_det.pth\"\n",
        "save_icevision_checkpoint(\n",
        "    model,\n",
        "    model_name='mmdet.retinanet',\n",
        "    backbone_name='resnet50_fpn_1x',\n",
        "    classes=m.get_classes(),\n",
        "    img_size=224,\n",
        "    filename=checkpoint_path,\n",
        "    meta={\"icevision_version\": \"0.12.0\"}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQSGl36m14RR",
        "outputId": "44da498d-b5cf-4b45-a1a1-ecd8360d5ed2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "id": "cLD5YOpb3vhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb52217-d967-4ce1-c73c-f48f75f14382"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1mThe mmdet config folder already exists. No need to downloaded it. Path : /root/.icevision/mmdetection_configs/mmdetection_configs-2.20.1/configs\u001b[0m | \u001b[36micevision.models.mmdet.download_configs\u001b[0m:\u001b[36mdownload_mmdet_configs\u001b[0m:\u001b[36m17\u001b[0m\n",
            "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1mThe mmseg config folder already exists. No need to downloaded it. Path : /root/.icevision/mmsegmentation_configs/mmsegmentation_configs-0.17.0/configs\u001b[0m | \u001b[36micevision.models.mmseg.download_configs\u001b[0m:\u001b[36mdownload_mmseg_configs\u001b[0m:\u001b[36m19\u001b[0m\n",
            "100% 1309/1309 [00:00<00:00, 12864.28it/s]\n",
            "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1m\u001b[34m\u001b[1mAutofixing records\u001b[0m\u001b[1m\u001b[34m\u001b[0m\u001b[1m\u001b[0m | \u001b[36micevision.parsers.parser\u001b[0m:\u001b[36mparse\u001b[0m:\u001b[36m122\u001b[0m\n",
            "100% 469/469 [00:00<00:00, 18707.30it/s]\n",
            "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.9/site-packages/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
            "  warnings.warn(\n",
            "2024-06-30 19:15:00,471 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
            "2024-06-30 19:15:00,471 - mmcv - INFO - load model from: torchvision://resnet50\n",
            "2024-06-30 19:15:00,471 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
            "2024-06-30 19:15:00,594 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "2024-06-30 19:15:00,622 - mmcv - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
            "2024-06-30 19:15:00,678 - mmcv - INFO - initialize RetinaHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'retina_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
            "2024-06-30 19:15:00,713 - mmcv - INFO - \n",
            "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,713 - mmcv - INFO - \n",
            "backbone.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,713 - mmcv - INFO - \n",
            "backbone.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,713 - mmcv - INFO - \n",
            "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,714 - mmcv - INFO - \n",
            "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,715 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,716 - mmcv - INFO - \n",
            "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,717 - mmcv - INFO - \n",
            "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,718 - mmcv - INFO - \n",
            "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,719 - mmcv - INFO - \n",
            "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,766 - mmcv - INFO - \n",
            "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,766 - mmcv - INFO - \n",
            "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,766 - mmcv - INFO - \n",
            "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,766 - mmcv - INFO - \n",
            "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,766 - mmcv - INFO - \n",
            "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,766 - mmcv - INFO - \n",
            "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,766 - mmcv - INFO - \n",
            "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,766 - mmcv - INFO - \n",
            "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,767 - mmcv - INFO - \n",
            "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,768 - mmcv - INFO - \n",
            "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.fpn_convs.3.conv.weight - torch.Size([256, 2048, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,769 - mmcv - INFO - \n",
            "neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "neck.fpn_convs.4.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.cls_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.cls_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.cls_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.cls_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.cls_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.cls_convs.3.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.reg_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.reg_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.reg_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.reg_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.reg_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.reg_convs.3.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:15:00,770 - mmcv - INFO - \n",
            "bbox_head.retina_cls.weight - torch.Size([27, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
            " \n",
            "2024-06-30 19:15:00,771 - mmcv - INFO - \n",
            "bbox_head.retina_cls.bias - torch.Size([27]): \n",
            "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
            " \n",
            "2024-06-30 19:15:00,771 - mmcv - INFO - \n",
            "bbox_head.retina_reg.weight - torch.Size([36, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:15:00,771 - mmcv - INFO - \n",
            "bbox_head.retina_reg.bias - torch.Size([36]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "load checkpoint from local path: checkpoints/retinanet/retinanet_r50_fpn_1x_coco_20200130-c2398f9e.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for bbox_head.retina_cls.weight: copying a param with shape torch.Size([720, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([27, 256, 3, 3]).\n",
            "size mismatch for bbox_head.retina_cls.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([27]).\n",
            "epoch     train_loss  valid_loss  COCOMetric  time    \n",
            "/usr/local/lib/python3.9/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
            "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
            "/usr/local/lib/python3.9/site-packages/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
            "  warnings.warn(\n",
            "0         1.050621    0.658306    0.226149    00:25     \n",
            "epoch     train_loss  valid_loss  COCOMetric  time    \n",
            "0         0.609873    0.569318    0.296462    00:28     \n",
            "1         0.575219    0.547834    0.316050    00:27     \n",
            "2         0.549040    0.520552    0.370898    00:25     \n",
            "3         0.512251    0.483665    0.409791    00:26     \n",
            "4         0.496710    0.472904    0.421575    00:27     \n",
            "5         0.475470    0.452958    0.441119    00:28     \n",
            "6         0.459884    0.433862    0.467758    00:27     \n",
            "7         0.445575    0.441327    0.474937    00:25     \n",
            "8         0.441487    0.424937    0.486571    00:27     \n",
            "9         0.428827    0.402081    0.505964    00:25     \n",
            "10        0.413058    0.380931    0.528952    00:34     \n",
            "11        0.396249    0.387629    0.529761    00:27     \n",
            "12        0.386504    0.374787    0.536269    00:25     \n",
            "13        0.378829    0.360743    0.559629    00:27     \n",
            "14        0.370647    0.354350    0.552622    00:25     \n",
            "15        0.363960    0.365236    0.554433    00:28     \n",
            "16        0.350803    0.332024    0.588405    00:26     \n",
            "17        0.344942    0.342735    0.588868    00:26     \n",
            "18        0.337679    0.323752    0.591040    00:26     \n",
            "19        0.335524    0.322114    0.585266    00:25     \n",
            "20        0.329847    0.309207    0.610559    00:27     \n",
            "21        0.328126    0.309592    0.605923    00:27     \n",
            "22        0.318432    0.304546    0.610208    00:24     \n",
            "23        0.312113    0.288483    0.625113    00:26     \n",
            "24        0.304835    0.294530    0.631701    00:23     \n",
            "25        0.303079    0.283144    0.629172    00:28     \n",
            "26        0.298987    0.296328    0.622977    00:23     \n",
            "27        0.291049    0.262556    0.649069    00:26     \n",
            "28        0.288739    0.271621    0.643241    00:24     \n",
            "29        0.284328    0.275893    0.637198    00:26     \n",
            "30        0.270547    0.269297    0.644184    00:26     \n",
            "31        0.269882    0.278488    0.626057    00:24     \n",
            "32        0.279503    0.262314    0.652460    00:25     \n",
            "33        0.266194    0.287137    0.614291    00:24     \n",
            "34        0.266751    0.262638    0.657691    00:25     \n",
            "35        0.275725    0.254584    0.662414    00:28     \n",
            "36        0.256918    0.247926    0.665613    00:25     \n",
            "37        0.257490    0.260532    0.650751    00:24     \n",
            "38        0.251565    0.249026    0.660736    00:25     \n",
            "39        0.251371    0.259586    0.650448    00:23     \n",
            "40        0.250282    0.258634    0.656183    00:30     \n",
            "41        0.249480    0.259337    0.656003    00:22     \n",
            "42        0.246891    0.252793    0.653843    00:26     \n",
            "43        0.243902    0.236983    0.681313    00:24     \n",
            "44        0.254345    0.245885    0.664879    00:25     \n",
            "45        0.248613    0.239943    0.675325    00:28     \n",
            "46        0.252932    0.246551    0.673054    00:25     \n",
            "47        0.250016    0.249322    0.660831    00:26     \n",
            "48        0.245507    0.242190    0.675153    00:24     \n",
            "49        0.247359    0.250148    0.654588    00:25     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test model"
      ],
      "metadata": {
        "id": "rVIx8xT2P7Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.py\n",
        "from icevision.all import *\n",
        "from icevision.models import *\n",
        "from icevision.core import BaseRecord\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "row_traincsv_data_path = os.path.join(r\"/content/data/train.csv\")\n",
        "df = pd.read_csv(row_traincsv_data_path)\n",
        "\n",
        "df.rename(columns={\"class\":\"label\"},inplace=True)\n",
        "\n",
        "train_annotation_path = os.path.join(r\"/content/data/yolo-animal-detection-small\",\"train_annotation.csv\")\n",
        "df.to_csv(train_annotation_path,index=False)\n",
        "df = pd.read_csv(train_annotation_path)\n",
        "\n",
        "template_record = ObjectDetectionRecord()\n",
        "\n",
        "class AmDetec(Parser):\n",
        "    def __init__(self,template_record):\n",
        "        super().__init__(template_record=template_record)\n",
        "\n",
        "        self.df = pd.read_csv(train_annotation_path)\n",
        "        self.class_map = ClassMap(list(self.df[\"label\"].unique())) # {\"background\":0,\"cat\":1,\"dog\":2}\n",
        "\n",
        "    def __iter__(self) -> Any:\n",
        "        for o in self.df.itertuples():\n",
        "            yield o   #จะคืนค่าทีละแถวแทนที่จะคืนค่าทั้งหมดในคราวเดียว\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def record_id(self,o) -> Hashable:\n",
        "        return o.filename\n",
        "    def parse_fields(self, o, record, is_new):\n",
        "        if is_new:\n",
        "            record.set_filepath(os.path.join(r\"/content/data/yolo-animal-detection-small\",\"train\",o.filename)) #setไฟล์pathเพื่อ train\n",
        "            record.set_img_size(ImgSize(width=o.width,height=o.height))\n",
        "            record.detection.set_class_map(self.class_map)\n",
        "        record.detection.add_bboxes([BBox.from_xyxy(o.xmin,o.ymin,o.xmax,o.ymax)])\n",
        "        record.detection.add_labels([o.label])\n",
        "\n",
        "parser = AmDetec(template_record=template_record)\n",
        "train_record,val_record = parser.parse()\n",
        "model_type = models.mmdet.retinanet\n",
        "backbone = model_type.backbones.resnet50_fpn_1x\n",
        "\n",
        "train_tramform = tfms.A.Adapter([*tfms.A.aug_tfms(size=224,presize=512),tfms.A.Normalize()])\n",
        "valid_tramform = tfms.A.Adapter([*tfms.A.resize_and_pad(224),tfms.A.Normalize()])\n",
        "\n",
        "\n",
        "train_set = Dataset(train_record,train_tramform)\n",
        "val_set = Dataset(val_record,valid_tramform)\n",
        "\n",
        "model_loaded = model_from_checkpoint(\"/content/monkeycatdog_det.pth\")\n",
        "model_type = model_loaded[\"model_type\"]\n",
        "backbone = model_loaded[\"backbone\"]\n",
        "class_map = model_loaded[\"class_map\"]\n",
        "img_size = model_loaded[\"img_size\"]\n",
        "\n",
        "model_type.show_results(model_loaded[\"model\"], val_set, detection_threshold=0.4)\n",
        "\n",
        "infer_dl = model_type.infer_dl(val_set, batch_size=4, shuffle=False) #อนุมานให้้ valset ทำเป็น dataloader แล้วเอาไป ทำการสร้างbbox ผ่าน\n",
        "\n",
        "#retinanet infer_dl = model_type.infer_dl(val_set, batch_size=4, shuffle=False): ทำการสร้าง DataLoader (infer_dl) จากชุดข้อมูลที่ต้องการทำนาย (val_set) โดยที่จำนวน batch คือ 4 และไม่มีการสลับข้อมูล (shuffle=False)\n",
        "# โดย DataLoader นี้จะถูกใช้ในการส่งภาพไปให้กับโมเดล RetinaNet เพื่อทำการตรวจจับวัตถุ (object detection) บนภาพเหล่านั้นๆ และคืนค่า bounding box ที่โมเดลคาดการณ์ได้ในแต่ละภาพ.\n",
        "\n",
        "preds = model_type.predict_from_dl(model_loaded[\"model\"], infer_dl, keep_images=True) #นำ รูปใน bbox ไป classification ใน resnet 50\n",
        "\n",
        "#preds = model_type.predict_from_dl(model_loaded[\"model\"], infer_dl, keep_images=True): นำ DataLoader (infer_dl) ที่ได้มาใช้ในการทำนายด้วยโมเดลที่โหลดมาจาก checkpoint (model_loaded[\"model\"])\n",
        "# โดยทำการตรวจจับวัตถุในภาพที่อยู่ใน bounding box ที่ได้แล้ว และทำการจำแนกประเภทของวัตถุใน bounding box โดยใช้ ResNet-50 ที่เรียนรู้มาแล้วจากภาพที่อยู่ใน bounding box นั้นๆ ซึ่งผลลัพธ์ที่ได้จะเป็นรายการของ predictions พร้อมกับภาพที่ถูกจัดประเภทไว้ในแต่ละ bounding box.\n",
        "\n",
        "#พารามิเตอร์ keep_images=True ที่ถูกใช้ในฟังก์ชัน model_type.predict_from_dl() มีหน้าที่บอกให้ฟังก์ชันเก็บภาพที่ผ่านการประมวลผล (inference) โดยโมเดลไว้ด้วย นั่นหมายความว่า เมื่อเราทำการทำนาย (inferencing) บนภาพใน DataLoader แล้ว\n",
        "# ไม่เพียงแค่ส่งผลลัพธ์ที่เป็นการจัดประเภท (classification) หรือตรวจจับวัตถุ (object detection) กลับมาเท่านั้น แต่ยังเก็บภาพต้นฉบับที่ผ่านการประมวลผลของโมเดลไว้ด้วยด้วย\n",
        "#การทำให้ฟังก์ชัน predict_from_dl() เก็บภาพต้นฉบับนี้เอาไว้เป็นไปได้เพื่อใช้ในการแสดงผลหรือการตรวจสอบผลลัพธ์ทีหลัง หรือในการวิเคราะห์เพิ่มเติมโดยไม่ต้องใช้ภาพต้นฉบับใหม่เสมอไป ซึ่งเป็นประโยชน์ในการลดการใช้ทรัพยากรและเพิ่มประสิทธิภาพของการทำงานโดยรวม\n",
        "\n",
        "## สมมติว่า preds เป็นผลลัพธ์ที่ได้จาก predict_from_dl()\n",
        "#for result in preds:\n",
        "    # ดูคีย์ทั้งหมดใน dictionary ของผลลัพธ์\n",
        "#    print(result.keys())\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "imgA = show_preds(preds=preds[:4])\n",
        "plt.axis('off')\n",
        "plt.savefig(\"/content/imgRESULT1.jpg\")\n",
        "plt.close()\n",
        "\n",
        "img = Image.open((glob.glob(os.path.join(r\"/content/data/yolo-animal-detection-small/train\",\"*.jpg\")))[4])\n",
        "pred_dict  = model_type.end2end_detect(img, valid_tramform, model_loaded[\"model\"], class_map=class_map, detection_threshold=0.5)\n",
        "imgg = pred_dict['img']\n",
        "imgg.save(\"/content/imgRESULT2.jpg\")\n",
        "\n",
        "print(pred_dict.keys())\n",
        "\n",
        "for i in pred_dict.keys():\n",
        "  print(pred_dict[i])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goVm1MVy4mEf",
        "outputId": "d0bd3b4b-faeb-4e18-c3c0-3049a52f2d31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py"
      ],
      "metadata": {
        "id": "yijfCcGs5KQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882dce6d-ba0e-4e8c-9ecf-e2a6f6aacfc5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1mThe mmdet config folder already exists. No need to downloaded it. Path : /root/.icevision/mmdetection_configs/mmdetection_configs-2.20.1/configs\u001b[0m | \u001b[36micevision.models.mmdet.download_configs\u001b[0m:\u001b[36mdownload_mmdet_configs\u001b[0m:\u001b[36m17\u001b[0m\n",
            "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1mThe mmseg config folder already exists. No need to downloaded it. Path : /root/.icevision/mmsegmentation_configs/mmsegmentation_configs-0.17.0/configs\u001b[0m | \u001b[36micevision.models.mmseg.download_configs\u001b[0m:\u001b[36mdownload_mmseg_configs\u001b[0m:\u001b[36m19\u001b[0m\n",
            "100% 1309/1309 [00:00<00:00, 12512.49it/s]\n",
            "\u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m - \u001b[1m\u001b[34m\u001b[1mAutofixing records\u001b[0m\u001b[1m\u001b[34m\u001b[0m\u001b[1m\u001b[0m | \u001b[36micevision.parsers.parser\u001b[0m:\u001b[36mparse\u001b[0m:\u001b[36m122\u001b[0m\n",
            "100% 469/469 [00:00<00:00, 18509.97it/s]\n",
            "load checkpoint from local path: /content/monkeycatdog_det.pth\n",
            "/usr/local/lib/python3.9/site-packages/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
            "  warnings.warn(\n",
            "2024-06-30 19:39:46,547 - mmcv - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
            "2024-06-30 19:39:46,547 - mmcv - INFO - load model from: torchvision://resnet50\n",
            "2024-06-30 19:39:46,547 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
            "2024-06-30 19:39:46,669 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "2024-06-30 19:39:46,697 - mmcv - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
            "2024-06-30 19:39:46,753 - mmcv - INFO - initialize RetinaHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'retina_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
            "2024-06-30 19:39:46,792 - mmcv - INFO - \n",
            "backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,793 - mmcv - INFO - \n",
            "backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.1.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.1.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.bn1.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.bn1.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.bn2.weight - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.bn2.bias - torch.Size([64]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.bn3.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer1.2.bn3.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,794 - mmcv - INFO - \n",
            "backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,795 - mmcv - INFO - \n",
            "backbone.layer2.1.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.2.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.bn1.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.bn1.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.bn2.weight - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.bn2.bias - torch.Size([128]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.bn3.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer2.3.bn3.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,796 - mmcv - INFO - \n",
            "backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.1.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,797 - mmcv - INFO - \n",
            "backbone.layer3.2.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.2.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.2.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.2.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.2.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.2.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.3.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.4.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.4.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,798 - mmcv - INFO - \n",
            "backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,799 - mmcv - INFO - \n",
            "backbone.layer3.4.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,799 - mmcv - INFO - \n",
            "backbone.layer3.4.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,799 - mmcv - INFO - \n",
            "backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,799 - mmcv - INFO - \n",
            "backbone.layer3.4.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.4.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.bn1.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.bn1.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.bn2.weight - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.bn2.bias - torch.Size([256]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.bn3.weight - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer3.5.bn3.bias - torch.Size([1024]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,804 - mmcv - INFO - \n",
            "backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,805 - mmcv - INFO - \n",
            "backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.1.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.1.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.bn1.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.bn1.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.bn2.weight - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.bn2.bias - torch.Size([512]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.bn3.weight - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "backbone.layer4.2.bn3.bias - torch.Size([2048]): \n",
            "PretrainedInit: load from torchvision://resnet50 \n",
            " \n",
            "2024-06-30 19:39:46,806 - mmcv - INFO - \n",
            "neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.lateral_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.lateral_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.lateral_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.3.conv.weight - torch.Size([256, 2048, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.3.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,807 - mmcv - INFO - \n",
            "neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "XavierInit: gain=1, distribution=uniform, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "neck.fpn_convs.4.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.cls_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.cls_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.cls_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.cls_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.cls_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.cls_convs.3.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.reg_convs.0.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.reg_convs.1.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,808 - mmcv - INFO - \n",
            "bbox_head.reg_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,809 - mmcv - INFO - \n",
            "bbox_head.reg_convs.2.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,809 - mmcv - INFO - \n",
            "bbox_head.reg_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,809 - mmcv - INFO - \n",
            "bbox_head.reg_convs.3.conv.bias - torch.Size([256]): \n",
            "The value is the same before and after calling `init_weights` of RetinaNet  \n",
            " \n",
            "2024-06-30 19:39:46,809 - mmcv - INFO - \n",
            "bbox_head.retina_cls.weight - torch.Size([27, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
            " \n",
            "2024-06-30 19:39:46,809 - mmcv - INFO - \n",
            "bbox_head.retina_cls.bias - torch.Size([27]): \n",
            "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
            " \n",
            "2024-06-30 19:39:46,809 - mmcv - INFO - \n",
            "bbox_head.retina_reg.weight - torch.Size([36, 256, 3, 3]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "2024-06-30 19:39:46,809 - mmcv - INFO - \n",
            "bbox_head.retina_reg.bias - torch.Size([36]): \n",
            "NormalInit: mean=0, std=0.01, bias=0 \n",
            " \n",
            "/usr/local/lib/python3.9/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
            "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
            "/usr/local/lib/python3.9/site-packages/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
            "  warnings.warn(\n",
            "Figure(600x2400)\n",
            "100% 24/24 [00:26<00:00,  1.08s/it]\n",
            "/usr/local/lib/python3.9/site-packages/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
            "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
            "/usr/local/lib/python3.9/site-packages/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
            "  warnings.warn(\n",
            "dict_keys(['detection', 'img', 'width', 'height'])\n",
            "{'bboxes': [<BBox (xmin:0, ymin:59, xmax:103, ymax:389)>, <BBox (xmin:69, ymin:19, xmax:203, ymax:398)>, <BBox (xmin:359, ymin:44, xmax:465, ymax:406)>, <BBox (xmin:181, ymin:29, xmax:287, ymax:394)>, <BBox (xmin:275, ymin:44, xmax:374, ymax:379)>, <BBox (xmin:133, ymin:38, xmax:251, ymax:394)>], 'labels': ['cat', 'cat', 'cat', 'cat', 'cat', 'cat'], 'label_ids': [1, 1, 1, 1, 1, 1], 'scores': array([    0.95198,     0.94361,     0.94054,     0.89642,     0.89087,     0.63886], dtype=float32)}\n",
            "<PIL.Image.Image image mode=RGB size=474x464 at 0x7C3C9A443F40>\n",
            "474\n",
            "464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list >requirements.txt"
      ],
      "metadata": {
        "id": "70vaaozgcKbO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvGbAawnszST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}